{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pyexpat import features\n",
    "import os.path as osp\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import argparse\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "from lib.utils import transf_to_CLIP_input, dummy_context_mgr\n",
    "from lib.utils import mkdir_p, get_rank\n",
    "from lib.datasets import prepare_data\n",
    "\n",
    "from models.inception import InceptionV3\n",
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "############   GAN   ############\n",
    "def train(dataloader, netG, netD, netC, text_encoder, image_encoder, optimizerG, optimizerD, scaler_G, scaler_D, args):\n",
    "    batch_size = args.batch_size\n",
    "    device = args.device\n",
    "    epoch = args.current_epoch\n",
    "    max_epoch = args.max_epoch\n",
    "    z_dim = args.z_dim\n",
    "    netG, netD, netC, image_encoder = netG.train(), netD.train(), netC.train(), image_encoder.train()\n",
    "    if (args.multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        loop = tqdm(total=len(dataloader))\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        ##############\n",
    "        # Train D  \n",
    "        ##############\n",
    "        optimizerD.zero_grad()\n",
    "        with torch.cuda.amp.autocast() if args.mixed_precision else dummy_context_mgr() as mpc:\n",
    "            # prepare_data\n",
    "            real, captions, CLIP_tokens, sent_emb, words_embs, keys = prepare_data(data, text_encoder, device)\n",
    "            real = real.requires_grad_()\n",
    "            sent_emb = sent_emb.requires_grad_()\n",
    "            words_embs = words_embs.requires_grad_()\n",
    "            # predict real\n",
    "            CLIP_real,real_emb = image_encoder(real)\n",
    "            real_feats = netD(CLIP_real)\n",
    "            pred_real, errD_real = predict_loss(netC, real_feats, sent_emb, negtive=False)\n",
    "            # predict mismatch\n",
    "            mis_sent_emb = torch.cat((sent_emb[1:], sent_emb[0:1]), dim=0).detach()\n",
    "            _, errD_mis = predict_loss(netC, real_feats, mis_sent_emb, negtive=True)\n",
    "            # synthesize fake images\n",
    "            noise = torch.randn(batch_size, z_dim).to(device)\n",
    "            fake = netG(noise, sent_emb)\n",
    "            CLIP_fake, fake_emb = image_encoder(fake)\n",
    "            fake_feats = netD(CLIP_fake.detach())\n",
    "            _, errD_fake = predict_loss(netC, fake_feats, sent_emb, negtive=True)\n",
    "        # MA-GP\n",
    "        if args.mixed_precision:\n",
    "            errD_MAGP = MA_GP_MP(CLIP_real, sent_emb, pred_real, scaler_D)\n",
    "        else:\n",
    "            errD_MAGP = MA_GP_FP32(CLIP_real, sent_emb, pred_real)\n",
    "        # whole D loss\n",
    "        with torch.cuda.amp.autocast() if args.mixed_precision else dummy_context_mgr() as mpc:\n",
    "            errD = errD_real + (errD_fake + errD_mis)/2.0 + errD_MAGP\n",
    "        # update D\n",
    "        if args.mixed_precision:\n",
    "            scaler_D.scale(errD).backward()\n",
    "            scaler_D.step(optimizerD)\n",
    "            scaler_D.update()\n",
    "            if scaler_D.get_scale()<args.scaler_min:\n",
    "                scaler_D.update(16384.0)\n",
    "        else:\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "        ##############\n",
    "        # Train G  \n",
    "        ##############\n",
    "        optimizerG.zero_grad()\n",
    "        with torch.cuda.amp.autocast() if args.mixed_precision else dummy_context_mgr() as mpc:\n",
    "            fake_feats = netD(CLIP_fake)\n",
    "            output = netC(fake_feats, sent_emb)\n",
    "            text_img_sim = torch.cosine_similarity(fake_emb, sent_emb).mean()\n",
    "            errG = -output.mean() - args.sim_w*text_img_sim\n",
    "        if args.mixed_precision:\n",
    "            scaler_G.scale(errG).backward()\n",
    "            scaler_G.step(optimizerG)\n",
    "            scaler_G.update()\n",
    "            if scaler_G.get_scale()<args.scaler_min:\n",
    "                scaler_G.update(16384.0)\n",
    "        else:\n",
    "            errG.backward()\n",
    "            optimizerG.step()\n",
    "        # update loop information\n",
    "        if (args.multi_gpus==True) and (get_rank() != 0):\n",
    "            None\n",
    "        else:\n",
    "            loop.update(1)\n",
    "            loop.set_description(f'Train Epoch [{epoch}/{max_epoch}]')\n",
    "            loop.set_postfix()\n",
    "    if (args.multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        loop.close()\n",
    "\n",
    "\n",
    "def test(dataloader, text_encoder, netG, PTM, device, m1, s1, epoch, max_epoch, times, z_dim, batch_size):\n",
    "    FID, TI_sim = calculate_FID_CLIP_sim(dataloader, text_encoder, netG, PTM, device, m1, s1, epoch, max_epoch, times, z_dim, batch_size)\n",
    "    return FID, TI_sim\n",
    "\n",
    "\n",
    "def save_model(netG, netD, netC, optG, optD, epoch, multi_gpus, step, save_path):\n",
    "    if (multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        state = {'model': {'netG': netG.state_dict(), 'netD': netD.state_dict(), 'netC': netC.state_dict()}, \\\n",
    "                'optimizers': {'optimizer_G': optG.state_dict(), 'optimizer_D': optD.state_dict()},\\\n",
    "                'epoch': epoch}\n",
    "        torch.save(state, '%s/state_epoch_%03d_%03d.pth' % (save_path, epoch, step))\n",
    "\n",
    "\n",
    "#########   MAGP   ########\n",
    "def MA_GP_MP(img, sent, out, scaler):\n",
    "    grads = torch.autograd.grad(outputs=scaler.scale(out),\n",
    "                            inputs=(img, sent),\n",
    "                            grad_outputs=torch.ones_like(out),\n",
    "                            retain_graph=True,\n",
    "                            create_graph=True,\n",
    "                            only_inputs=True)\n",
    "    inv_scale = 1./(scaler.get_scale()+float(\"1e-8\"))\n",
    "    #inv_scale = 1./scaler.get_scale()\n",
    "    grads = [grad * inv_scale for grad in grads]\n",
    "    with torch.cuda.amp.autocast():\n",
    "        grad0 = grads[0].view(grads[0].size(0), -1)\n",
    "        grad1 = grads[1].view(grads[1].size(0), -1)\n",
    "        grad = torch.cat((grad0,grad1),dim=1)                        \n",
    "        grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "        d_loss_gp =  2.0 * torch.mean((grad_l2norm) ** 6)\n",
    "    return d_loss_gp\n",
    "\n",
    "\n",
    "def MA_GP_FP32(img, sent, out):\n",
    "    grads = torch.autograd.grad(outputs=out,\n",
    "                            inputs=(img, sent),\n",
    "                            grad_outputs=torch.ones(out.size()).cuda(),\n",
    "                            retain_graph=True,\n",
    "                            create_graph=True,\n",
    "                            only_inputs=True)\n",
    "    grad0 = grads[0].view(grads[0].size(0), -1)\n",
    "    grad1 = grads[1].view(grads[1].size(0), -1)\n",
    "    grad = torch.cat((grad0,grad1),dim=1)                        \n",
    "    grad_l2norm = torch.sqrt(torch.sum(grad ** 2, dim=1))\n",
    "    d_loss_gp =  2.0 * torch.mean((grad_l2norm) ** 6)\n",
    "    return d_loss_gp\n",
    "\n",
    "\n",
    "def sample(dataloader, netG, text_encoder, save_dir, device, multi_gpus, z_dim, stamp):\n",
    "    netG.eval()\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        ######################################################\n",
    "        # (1) Prepare_data\n",
    "        ######################################################\n",
    "        real, captions, CLIP_tokens, sent_emb, words_embs, keys = prepare_data(data, text_encoder, device)\n",
    "        ######################################################\n",
    "        # (2) Generate fake images\n",
    "        ######################################################\n",
    "        batch_size = sent_emb.size(0)\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(batch_size, z_dim).to(device)\n",
    "            fake_imgs = netG(noise, sent_emb, eval=True).float()\n",
    "            fake_imgs = torch.clamp(fake_imgs, -1., 1.)\n",
    "            if multi_gpus==True:\n",
    "                batch_img_name = 'step_%04d.png'%(step)\n",
    "                batch_img_save_dir  = osp.join(save_dir, 'batch', str('gpu%d'%(get_rank())), 'imgs')\n",
    "                batch_img_save_name = osp.join(batch_img_save_dir, batch_img_name)\n",
    "                batch_txt_name = 'step_%04d.txt'%(step)\n",
    "                batch_txt_save_dir  = osp.join(save_dir, 'batch', str('gpu%d'%(get_rank())), 'txts')\n",
    "                batch_txt_save_name = osp.join(batch_txt_save_dir, batch_txt_name)\n",
    "            else:\n",
    "                batch_img_name = 'step_%04d.png'%(step)\n",
    "                batch_img_save_dir  = osp.join(save_dir, 'batch', 'imgs')\n",
    "                batch_img_save_name = osp.join(batch_img_save_dir, batch_img_name)\n",
    "                batch_txt_name = 'step_%04d.txt'%(step)\n",
    "                batch_txt_save_dir  = osp.join(save_dir, 'batch', 'txts')\n",
    "                batch_txt_save_name = osp.join(batch_txt_save_dir, batch_txt_name)\n",
    "            mkdir_p(batch_img_save_dir)\n",
    "            vutils.save_image(fake_imgs.data, batch_img_save_name, nrow=8, value_range=(-1, 1), normalize=True)\n",
    "            mkdir_p(batch_txt_save_dir)\n",
    "            txt = open(batch_txt_save_name,'w')\n",
    "            for cap in captions:\n",
    "                txt.write(cap+'\\n')\n",
    "            txt.close()\n",
    "            for j in range(batch_size):\n",
    "                im = fake_imgs[j].data.cpu().numpy()\n",
    "                # [-1, 1] --> [0, 255]\n",
    "                im = (im + 1.0) * 127.5\n",
    "                im = im.astype(np.uint8)\n",
    "                im = np.transpose(im, (1, 2, 0))\n",
    "                im = Image.fromarray(im)\n",
    "                ######################################################\n",
    "                # (3) Save fake images\n",
    "                ######################################################      \n",
    "                if multi_gpus==True:\n",
    "                    single_img_name = 'batch_%04d.png'%(j)\n",
    "                    single_img_save_dir  = osp.join(save_dir, 'single', str('gpu%d'%(get_rank())), 'step%04d'%(step))\n",
    "                    single_img_save_name = osp.join(single_img_save_dir, single_img_name)\n",
    "                else:\n",
    "                    single_img_name = 'step_%04d.png'%(step)\n",
    "                    single_img_save_dir  = osp.join(save_dir, 'single', 'step%04d'%(step))\n",
    "                    single_img_save_name = osp.join(single_img_save_dir, single_img_name)   \n",
    "                mkdir_p(single_img_save_dir)   \n",
    "                im.save(single_img_save_name)\n",
    "        if (multi_gpus==True) and (get_rank() != 0):\n",
    "            None\n",
    "        else:\n",
    "            print('Step: %d' % (step))\n",
    "\n",
    "\n",
    "def calculate_FID_CLIP_sim(dataloader, text_encoder, netG, CLIP, device, m1, s1, epoch, max_epoch, times, z_dim, batch_size):\n",
    "    \"\"\" Calculates the FID \"\"\"\n",
    "    clip_cos = torch.FloatTensor([0.0]).to(device)\n",
    "    # prepare Inception V3\n",
    "    dims = 2048\n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "    model = InceptionV3([block_idx])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    netG.eval()\n",
    "    norm = transforms.Compose([\n",
    "        transforms.Normalize((-1, -1, -1), (2, 2, 2)),\n",
    "        transforms.Resize((299, 299)),\n",
    "        ])\n",
    "    n_gpu = dist.get_world_size()\n",
    "    dl_length = dataloader.__len__()\n",
    "    imgs_num = dl_length * n_gpu * batch_size * times\n",
    "    pred_arr = np.empty((imgs_num, dims))\n",
    "    if (n_gpu!=1) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        loop = tqdm(total=int(dl_length*times))\n",
    "    for time in range(times):\n",
    "        for i, data in enumerate(dataloader):\n",
    "            start = i * batch_size * n_gpu + time * dl_length * n_gpu * batch_size\n",
    "            end = start + batch_size * n_gpu\n",
    "            ######################################################\n",
    "            # (1) Prepare_data\n",
    "            ######################################################\n",
    "            imgs, captions, CLIP_tokens, sent_emb, words_embs, keys = prepare_data(data, text_encoder, device)\n",
    "            ######################################################\n",
    "            # (2) Generate fake images\n",
    "            ######################################################\n",
    "            batch_size = sent_emb.size(0)\n",
    "            netG.eval()\n",
    "            with torch.no_grad():\n",
    "                noise = torch.randn(batch_size, z_dim).to(device)\n",
    "                fake_imgs = netG(noise,sent_emb,eval=True).float()\n",
    "                # norm_ip(fake_imgs, -1, 1)\n",
    "                fake_imgs = torch.clamp(fake_imgs, -1., 1.)\n",
    "                fake_imgs = torch.nan_to_num(fake_imgs, nan=-1.0, posinf=1.0, neginf=-1.0)\n",
    "                clip_sim = calc_clip_sim(CLIP, fake_imgs, CLIP_tokens, device)\n",
    "                clip_cos = clip_cos + clip_sim\n",
    "                fake = norm(fake_imgs)\n",
    "                pred = model(fake)[0]\n",
    "                if pred.shape[2] != 1 or pred.shape[3] != 1:\n",
    "                    pred = adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
    "                # concat pred from multi GPUs\n",
    "                output = list(torch.empty_like(pred) for _ in range(n_gpu))\n",
    "                dist.all_gather(output, pred)\n",
    "                pred_all = torch.cat(output, dim=0).squeeze(-1).squeeze(-1)\n",
    "                pred_arr[start:end] = pred_all.cpu().data.numpy()\n",
    "            # update loop information\n",
    "            if (n_gpu!=1) and (get_rank() != 0):\n",
    "                None\n",
    "            else:\n",
    "                loop.update(1)\n",
    "                if epoch==-1:\n",
    "                    loop.set_description('Evaluating]')\n",
    "                else:\n",
    "                    loop.set_description(f'Eval Epoch [{epoch}/{max_epoch}]')\n",
    "                loop.set_postfix()\n",
    "    if (n_gpu!=1) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        loop.close()\n",
    "    # CLIP-score\n",
    "    CLIP_score_gather = list(torch.empty_like(clip_cos) for _ in range(n_gpu))\n",
    "    dist.all_gather(CLIP_score_gather, clip_cos)\n",
    "    clip_score = torch.cat(CLIP_score_gather, dim=0).mean().item()/(dl_length*times)\n",
    "    # FID\n",
    "    m2 = np.mean(pred_arr, axis=0)\n",
    "    s2 = np.cov(pred_arr, rowvar=False)\n",
    "    fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
    "    return fid_value,clip_score\n",
    "\n",
    "\n",
    "def calc_clip_sim(clip, fake, caps_clip, device):\n",
    "    ''' calculate cosine similarity between fake and text features,\n",
    "    '''\n",
    "    # Calculate features\n",
    "    fake = transf_to_CLIP_input(fake)\n",
    "    fake_features = clip.encode_image(fake)\n",
    "    text_features = clip.encode_text(caps_clip)\n",
    "    text_img_sim = torch.cosine_similarity(fake_features, text_features).mean()\n",
    "    return text_img_sim\n",
    "\n",
    "\n",
    "def sample_one_batch(noise, sent, netG, multi_gpus, epoch, img_save_dir, writer):\n",
    "    if (multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        netG.eval()\n",
    "        with torch.no_grad():\n",
    "            B = noise.size(0)\n",
    "            fixed_results_train = generate_samples(noise[:B//2], sent[:B//2], netG).cpu()\n",
    "            torch.cuda.empty_cache()\n",
    "            fixed_results_test = generate_samples(noise[B//2:], sent[B//2:], netG).cpu()\n",
    "            torch.cuda.empty_cache()\n",
    "            fixed_results = torch.cat((fixed_results_train, fixed_results_test), dim=0)\n",
    "        img_name = 'samples_epoch_%03d.png'%(epoch)\n",
    "        img_save_path = osp.join(img_save_dir, img_name)\n",
    "        vutils.save_image(fixed_results.data, img_save_path, nrow=8, value_range=(-1, 1), normalize=True)\n",
    "\n",
    "\n",
    "def generate_samples(noise, caption, model):\n",
    "    with torch.no_grad():\n",
    "        fake = model(noise, caption, eval=True)\n",
    "    return fake\n",
    "\n",
    "\n",
    "def predict_loss(predictor, img_feature, text_feature, negtive):\n",
    "    output = predictor(img_feature, text_feature)\n",
    "    err = hinge_loss(output, negtive)\n",
    "    return output,err\n",
    "\n",
    "\n",
    "def hinge_loss(output, negtive):\n",
    "    if negtive==False:\n",
    "        err = torch.mean(F.relu(1. - output))\n",
    "    else:\n",
    "        err = torch.mean(F.relu(1. + output))\n",
    "    return err\n",
    "\n",
    "\n",
    "def logit_loss(output, negtive):\n",
    "    batch_size = output.size(0)\n",
    "    real_labels = torch.FloatTensor(batch_size,1).fill_(1).to(output.device)\n",
    "    fake_labels = torch.FloatTensor(batch_size,1).fill_(0).to(output.device)\n",
    "    output = nn.Sigmoid()(output)\n",
    "    if negtive==False:\n",
    "        err = nn.BCELoss()(output, real_labels)\n",
    "    else:\n",
    "        err = nn.BCELoss()(output, fake_labels)\n",
    "    return err\n",
    "\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "    '''\n",
    "    print('&'*20)\n",
    "    print(sigma1)#, sigma1.type())\n",
    "    print('&'*20)\n",
    "    print(sigma2)#, sigma2.type())\n",
    "    '''\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
