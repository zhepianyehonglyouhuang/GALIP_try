{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b92e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import errno\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import torch\n",
    "from torch import distributed as dist\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "from PIL import Image\n",
    "\n",
    "import importlib\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn.functional as F\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "\n",
    "\n",
    "def choose_model(model):\n",
    "    '''choose models\n",
    "    '''\n",
    "    model = importlib.import_module(\".%s\"%(model), \"models\")\n",
    "    NetG, NetD, NetC, CLIP_IMG_ENCODER, CLIP_TXT_ENCODER = model.NetG, model.NetD, model.NetC, model.CLIP_IMG_ENCODER, model.CLIP_TXT_ENCODER\n",
    "    return NetG,NetD,NetC,CLIP_IMG_ENCODER, CLIP_TXT_ENCODER\n",
    "\n",
    "\n",
    "def params_count(model):\n",
    "    model_size = np.sum([p.numel() for p in model.parameters()]).item()\n",
    "    return model_size\n",
    "\n",
    "\n",
    "def get_time_stamp():\n",
    "    now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "    timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')  \n",
    "    return timestamp\n",
    "\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "def load_npz(path):\n",
    "    f = np.load(path)\n",
    "    m, s = f['mu'][:], f['sigma'][:]\n",
    "    f.close()\n",
    "    return m, s\n",
    "\n",
    "# config\n",
    "def load_yaml(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        cfg = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def str2bool_dict(dict):\n",
    "    for key,value in dict.items():\n",
    "        if type(value)==str:\n",
    "            if value.lower() in ('yes','true'):\n",
    "                dict[key] = True\n",
    "            elif value.lower() in ('no','false'):\n",
    "                dict[key] = False\n",
    "            else:\n",
    "                None\n",
    "    return dict\n",
    "\n",
    "\n",
    "def merge_args_yaml(args):\n",
    "    if args.cfg_file is not None:\n",
    "        opt = vars(args)\n",
    "        args = load_yaml(args.cfg_file)\n",
    "        args.update(opt)\n",
    "        args = str2bool_dict(args)\n",
    "        args = edict(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def save_args(save_path, args):\n",
    "    fp = open(save_path, 'w')\n",
    "    fp.write(yaml.dump(args))\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "def read_txt_file(txt_file):\n",
    "    content = []\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip('\\n')\n",
    "            content.append(line)\n",
    "    return content\n",
    "\n",
    "\n",
    "def get_rank():\n",
    "    if not dist.is_available():\n",
    "        return 0\n",
    "    if not dist.is_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()\n",
    "\n",
    "\n",
    "def load_opt_weights(optimizer, weights):\n",
    "    optimizer.load_state_dict(weights)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def load_models_opt(netG, netD, netC, optim_G, optim_D, path, multi_gpus):\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    netG = load_model_weights(netG, checkpoint['model']['netG'], multi_gpus)\n",
    "    netD = load_model_weights(netD, checkpoint['model']['netD'], multi_gpus)\n",
    "    netC = load_model_weights(netC, checkpoint['model']['netC'], multi_gpus)\n",
    "    optim_G = load_opt_weights(optim_G, checkpoint['optimizers']['optimizer_G'])\n",
    "    optim_D = load_opt_weights(optim_D, checkpoint['optimizers']['optimizer_D'])\n",
    "    return netG, netD, netC, optim_G, optim_D\n",
    "\n",
    "\n",
    "def load_models(netG, netD, netC, path):\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    netG = load_model_weights(netG, checkpoint['model']['netG'])\n",
    "    netD = load_model_weights(netD, checkpoint['model']['netD'])\n",
    "    netC = load_model_weights(netC, checkpoint['model']['netC'])\n",
    "    return netG, netD, netC\n",
    "\n",
    "\n",
    "def load_netG(netG, path, multi_gpus, train):\n",
    "    checkpoint = torch.load(path, map_location=\"cpu\")\n",
    "    netG = load_model_weights(netG, checkpoint['model']['netG'], multi_gpus, train)\n",
    "    return netG\n",
    "\n",
    "\n",
    "def load_model_weights(model, weights, multi_gpus, train=True):\n",
    "    if list(weights.keys())[0].find('module')==-1:\n",
    "        pretrained_with_multi_gpu = False\n",
    "    else:\n",
    "        pretrained_with_multi_gpu = True\n",
    "    if (multi_gpus==False) or (train==False):\n",
    "        if pretrained_with_multi_gpu:\n",
    "            state_dict = {\n",
    "                key[7:]: value\n",
    "                for key, value in weights.items()\n",
    "            }\n",
    "        else:\n",
    "            state_dict = weights\n",
    "    else:\n",
    "        state_dict = weights\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_models_opt(netG, netD, netC, optG, optD, epoch, multi_gpus, save_path):\n",
    "    if (multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        state = {'model': {'netG': netG.state_dict(), 'netD': netD.state_dict(), 'netC': netC.state_dict()}, \\\n",
    "                'optimizers': {'optimizer_G': optG.state_dict(), 'optimizer_D': optD.state_dict()},\\\n",
    "                'epoch': epoch}\n",
    "        torch.save(state, '%s/state_epoch_%03d.pth' % (save_path, epoch))\n",
    "\n",
    "\n",
    "def save_models(netG, netD, netC, epoch, multi_gpus, save_path):\n",
    "    if (multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        state = {'model': {'netG': netG.state_dict(), 'netD': netD.state_dict(), 'netC': netC.state_dict()}}\n",
    "        torch.save(state, '%s/state_epoch_%03d.pth' % (save_path, epoch))\n",
    "\n",
    "\n",
    "def save_checkpoints(netG, netD, netC, optG, optD, scaler_G, scaler_D, epoch, multi_gpus, save_path):\n",
    "    if (multi_gpus==True) and (get_rank() != 0):\n",
    "        None\n",
    "    else:\n",
    "        state = {'model': {'netG': netG.state_dict(), 'netD': netD.state_dict(), 'netC': netC.state_dict()}, \\\n",
    "                'optimizers': {'optimizer_G': optG.state_dict(), 'optimizer_D': optD.state_dict()},\\\n",
    "                \"scalers\": {\"scaler_G\": scaler_G.state_dict(), \"scaler_D\": scaler_D.state_dict()},\\\n",
    "                'epoch': epoch}\n",
    "        torch.save(state, '%s/state_epoch_%03d.pth' % (save_path, epoch))\n",
    "\n",
    "\n",
    "def write_to_txt(filename, contents): \n",
    "    fh = open(filename, 'w') \n",
    "    fh.write(contents) \n",
    "    fh.close()\n",
    "\n",
    "\n",
    "def read_txt_file(txt_file):\n",
    "    # text_file: file path\n",
    "    content = []\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip('\\n')\n",
    "            content.append(line)\n",
    "    return content\n",
    "\n",
    "\n",
    "def save_img(img, path):\n",
    "    im = img.data.cpu().numpy()\n",
    "    # [-1, 1] --> [0, 255]\n",
    "    im = (im + 1.0) * 127.5\n",
    "    im = im.astype(np.uint8)\n",
    "    im = np.transpose(im, (1, 2, 0))\n",
    "    im = Image.fromarray(im)\n",
    "    im.save(path)\n",
    "\n",
    "\n",
    "def transf_to_CLIP_input(inputs):\n",
    "    device = inputs.device\n",
    "    if len(inputs.size()) != 4:\n",
    "        raise ValueError('Expect the (B, C, X, Y) tensor.')\n",
    "    else:\n",
    "        mean = torch.tensor([0.48145466, 0.4578275, 0.40821073])\\\n",
    "            .unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(device)\n",
    "        var = torch.tensor([0.26862954, 0.26130258, 0.27577711])\\\n",
    "            .unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(device)\n",
    "        inputs = F.interpolate(inputs*0.5+0.5, size=(224, 224))\n",
    "        inputs = ((inputs+1)*0.5-mean)/var\n",
    "        return inputs.float()\n",
    "\n",
    "\n",
    "class dummy_context_mgr():\n",
    "    def __enter__(self):\n",
    "        return None\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        return False\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
