{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c6a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy.random as random\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import clip as clip\n",
    "\n",
    "\n",
    "def get_fix_data(train_dl, test_dl, text_encoder, args):\n",
    "    fixed_image_train, _, _, fixed_sent_train, fixed_word_train, fixed_key_train = get_one_batch_data(train_dl, text_encoder, args)\n",
    "    fixed_image_test, _, _, fixed_sent_test, fixed_word_test, fixed_key_test= get_one_batch_data(test_dl, text_encoder, args)\n",
    "    fixed_image = torch.cat((fixed_image_train, fixed_image_test), dim=0)\n",
    "    fixed_sent = torch.cat((fixed_sent_train, fixed_sent_test), dim=0)\n",
    "    fixed_word = torch.cat((fixed_word_train, fixed_word_test), dim=0)\n",
    "    fixed_noise = torch.randn(fixed_image.size(0), args.z_dim).to(args.device)\n",
    "    return fixed_image, fixed_sent, fixed_word, fixed_noise\n",
    "\n",
    "\n",
    "def get_one_batch_data(dataloader, text_encoder, args):\n",
    "    data = next(iter(dataloader))\n",
    "    imgs, captions, CLIP_tokens, sent_emb, words_embs, keys = prepare_data(data, text_encoder, args.device)\n",
    "    return imgs, captions, CLIP_tokens, sent_emb, words_embs, keys\n",
    "\n",
    "\n",
    "def prepare_data(data, text_encoder, device):\n",
    "    imgs, captions, CLIP_tokens, keys = data\n",
    "    imgs, CLIP_tokens = imgs.to(device), CLIP_tokens.to(device)\n",
    "    sent_emb, words_embs = encode_tokens(text_encoder, CLIP_tokens)\n",
    "    return imgs, captions, CLIP_tokens, sent_emb, words_embs, keys\n",
    "\n",
    "\n",
    "def encode_tokens(text_encoder, caption):\n",
    "    # encode text\n",
    "    with torch.no_grad():\n",
    "        sent_emb,words_embs = text_encoder(caption)\n",
    "        sent_emb,words_embs = sent_emb.detach(), words_embs.detach()\n",
    "    return sent_emb, words_embs \n",
    "\n",
    "\n",
    "def get_imgs(img_path, bbox=None, transform=None, normalize=None):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    width, height = img.size\n",
    "    if bbox is not None:\n",
    "        r = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n",
    "        center_x = int((2 * bbox[0] + bbox[2]) / 2)\n",
    "        center_y = int((2 * bbox[1] + bbox[3]) / 2)\n",
    "        y1 = np.maximum(0, center_y - r)\n",
    "        y2 = np.minimum(height, center_y + r)\n",
    "        x1 = np.maximum(0, center_x - r)\n",
    "        x2 = np.minimum(width, center_x + r)\n",
    "        img = img.crop([x1, y1, x2, y2])\n",
    "    if transform is not None:\n",
    "        img = transform(img)\n",
    "    if normalize is not None:\n",
    "        img = normalize(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_caption(cap_path,clip_info):\n",
    "    eff_captions = []\n",
    "    with open(cap_path, \"r\") as f:\n",
    "        captions = f.read().encode('utf-8').decode('utf8').split('\\n')\n",
    "    for cap in captions:\n",
    "        if len(cap) != 0:\n",
    "            eff_captions.append(cap)\n",
    "    sent_ix = random.randint(0, len(eff_captions))\n",
    "    caption = eff_captions[sent_ix]\n",
    "    tokens = clip.tokenize(caption,truncate=True)\n",
    "    return caption, tokens[0]\n",
    "\n",
    "\n",
    "################################################################\n",
    "#                    Dataset\n",
    "################################################################\n",
    "class TextImgDataset(data.Dataset):\n",
    "    def __init__(self, split, transform=None, args=None):\n",
    "        self.transform = transform\n",
    "        self.clip4text = args.clip4text\n",
    "        self.data_dir = args.data_dir\n",
    "        self.dataset_name = args.dataset_name\n",
    "        self.norm = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ])\n",
    "        self.split=split\n",
    "        \n",
    "        if self.data_dir.find('birds') != -1:\n",
    "            self.bbox = self.load_bbox()\n",
    "        else:\n",
    "            self.bbox = None\n",
    "        self.split_dir = os.path.join(self.data_dir, split)\n",
    "        self.filenames = self.load_filenames(self.data_dir, split)\n",
    "        self.number_example = len(self.filenames)\n",
    "\n",
    "    def load_bbox(self):\n",
    "        data_dir = self.data_dir\n",
    "        bbox_path = os.path.join(data_dir, 'CUB_200_2011/bounding_boxes.txt')\n",
    "        df_bounding_boxes = pd.read_csv(bbox_path,\n",
    "                                        delim_whitespace=True,\n",
    "                                        header=None).astype(int)\n",
    "        #\n",
    "        filepath = os.path.join(data_dir, 'CUB_200_2011/images.txt')\n",
    "        df_filenames = \\\n",
    "            pd.read_csv(filepath, delim_whitespace=True, header=None)\n",
    "        filenames = df_filenames[1].tolist()\n",
    "        print('Total filenames: ', len(filenames), filenames[0])\n",
    "        #\n",
    "        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n",
    "        numImgs = len(filenames)\n",
    "        for i in range(0, numImgs):\n",
    "            # bbox = [x-left, y-top, width, height]\n",
    "            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "            key = filenames[i][:-4]\n",
    "            filename_bbox[key] = bbox\n",
    "        return filename_bbox\n",
    "\n",
    "    def load_filenames(self, data_dir, split):\n",
    "        filepath = '%s/%s/filenames.pickle' % (data_dir, split)\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                filenames = pickle.load(f)\n",
    "            print('Load filenames from: %s (%d)' % (filepath, len(filenames)))\n",
    "        else:\n",
    "            filenames = []\n",
    "        return filenames\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #\n",
    "        key = self.filenames[index]\n",
    "        data_dir = self.data_dir\n",
    "        #\n",
    "        if self.bbox is not None:\n",
    "            bbox = self.bbox[key]\n",
    "        else:\n",
    "            bbox = None\n",
    "        #\n",
    "        if self.dataset_name.lower().find('coco') != -1:\n",
    "            if self.split=='train':\n",
    "                img_name = '%s/images/train2014/jpg/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/%s.txt' % (data_dir, key)\n",
    "            else:\n",
    "                img_name = '%s/images/val2014/jpg/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/%s.txt' % (data_dir, key)\n",
    "        elif self.dataset_name.lower().find('cc3m') != -1:\n",
    "            if self.split=='train':\n",
    "                img_name = '%s/images/train/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/train/%s.txt' % (data_dir, key.split('_')[0])\n",
    "            else:\n",
    "                img_name = '%s/images/test/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/test/%s.txt' % (data_dir, key.split('_')[0])\n",
    "        elif self.dataset_name.lower().find('cc12m') != -1:\n",
    "            if self.split=='train':\n",
    "                img_name = '%s/images/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/%s.txt' % (data_dir, key.split('_')[0])\n",
    "            else:\n",
    "                img_name = '%s/images/%s.jpg' % (data_dir, key)\n",
    "                text_name = '%s/text/%s.txt' % (data_dir, key.split('_')[0])\n",
    "        else:\n",
    "            img_name = '%s/CUB_200_2011/images/%s.jpg' % (data_dir, key)\n",
    "            text_name = '%s/text/%s.txt' % (data_dir, key)\n",
    "        #\n",
    "        imgs = get_imgs(img_name, bbox, self.transform, normalize=self.norm)\n",
    "        caps,tokens = get_caption(text_name,self.clip4text)\n",
    "        return imgs, caps, tokens, key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
