{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59729a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import clip\n",
    "import importlib\n",
    "from lib.utils import choose_model\n",
    "\n",
    "\n",
    "###########   preparation   ############\n",
    "def load_clip(clip_info, device):\n",
    "    import clip as clip\n",
    "    model = clip.load(clip_info['type'], device=device)[0]\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_models(args):\n",
    "    device = args.device\n",
    "    local_rank = args.local_rank\n",
    "    multi_gpus = args.multi_gpus\n",
    "    CLIP4trn = load_clip(args.clip4trn, device).eval()\n",
    "    CLIP4evl = load_clip(args.clip4evl, device).eval()\n",
    "    NetG,NetD,NetC,CLIP_IMG_ENCODER,CLIP_TXT_ENCODER = choose_model(args.model)\n",
    "    # image encoder\n",
    "    CLIP_img_enc = CLIP_IMG_ENCODER(CLIP4trn).to(device)\n",
    "    for p in CLIP_img_enc.parameters():\n",
    "        p.requires_grad = False\n",
    "    CLIP_img_enc.eval()\n",
    "    # text encoder\n",
    "    CLIP_txt_enc = CLIP_TXT_ENCODER(CLIP4trn).to(device)\n",
    "    for p in CLIP_txt_enc.parameters():\n",
    "        p.requires_grad = False\n",
    "    CLIP_txt_enc.eval()\n",
    "    # GAN models\n",
    "    netG = NetG(args.nf, args.z_dim, args.cond_dim, args.imsize, args.ch_size, args.mixed_precision, CLIP4trn).to(device)\n",
    "    netD = NetD(args.nf, args.imsize, args.ch_size, args.mixed_precision).to(device)\n",
    "    netC = NetC(args.nf, args.cond_dim, args.mixed_precision).to(device)\n",
    "    if (args.multi_gpus) and (args.train):\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        netG = torch.nn.parallel.DistributedDataParallel(netG, broadcast_buffers=False,\n",
    "                                                          device_ids=[local_rank],\n",
    "                                                          output_device=local_rank, find_unused_parameters=True)\n",
    "        netD = torch.nn.parallel.DistributedDataParallel(netD, broadcast_buffers=False,\n",
    "                                                          device_ids=[local_rank],\n",
    "                                                          output_device=local_rank, find_unused_parameters=True)\n",
    "        netC = torch.nn.parallel.DistributedDataParallel(netC, broadcast_buffers=False,\n",
    "                                                          device_ids=[local_rank],\n",
    "                                                          output_device=local_rank, find_unused_parameters=True)\n",
    "    return CLIP4trn, CLIP4evl, CLIP_img_enc, CLIP_txt_enc, netG, netD, netC\n",
    "\n",
    "\n",
    "def prepare_dataset(args, split, transform):\n",
    "    if args.ch_size!=3:\n",
    "        imsize = 256\n",
    "    else:\n",
    "        imsize = args.imsize\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose([\n",
    "            transforms.Resize(int(imsize * 76 / 64)),\n",
    "            transforms.RandomCrop(imsize),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            ])\n",
    "    from lib.datasets import TextImgDataset as Dataset\n",
    "    dataset = Dataset(split=split, transform=image_transform, args=args)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def prepare_datasets(args, transform):\n",
    "    # train dataset\n",
    "    train_dataset = prepare_dataset(args, split='train', transform=transform)\n",
    "    # test dataset\n",
    "    val_dataset = prepare_dataset(args, split='test', transform=transform)\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "def prepare_dataloaders(args, transform=None):\n",
    "    batch_size = args.batch_size\n",
    "    num_workers = args.num_workers\n",
    "    train_dataset, valid_dataset = prepare_datasets(args, transform)\n",
    "    # train dataloader\n",
    "    if args.multi_gpus==True:\n",
    "        train_sampler = DistributedSampler(train_dataset)\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, drop_last=True,\n",
    "            num_workers=num_workers, sampler=train_sampler)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=batch_size, drop_last=True,\n",
    "            num_workers=num_workers, shuffle='True')\n",
    "    # valid dataloader\n",
    "    if args.multi_gpus==True:\n",
    "        valid_sampler = DistributedSampler(valid_dataset)\n",
    "        valid_dataloader = torch.utils.data.DataLoader(\n",
    "            valid_dataset, batch_size=batch_size, drop_last=True,\n",
    "            num_workers=num_workers, sampler=valid_sampler)\n",
    "    else:\n",
    "        valid_dataloader = torch.utils.data.DataLoader(\n",
    "            valid_dataset, batch_size=batch_size, drop_last=True,\n",
    "            num_workers=num_workers, shuffle='True')\n",
    "    return train_dataloader, valid_dataloader, \\\n",
    "            train_dataset, valid_dataset, train_sampler\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
